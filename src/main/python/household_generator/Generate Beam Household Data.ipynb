{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART I. Preparation:\n",
    "\n",
    "1. Create a working directory with the following folder structure:\n",
    "        <working_dir_name>/\n",
    "                          input/\n",
    "                          output/\n",
    "        \n",
    "2. Install [doppelganger](https://github.com/sidewalklabs/doppelganger.git):\n",
    "    \n",
    "        `pip install doppelganger`\n",
    "        \n",
    "3. Download household and population level PUMS data for your state form [this link](https://www.census.gov/programs-surveys/acs/data/pums.html) and save to your `input` folder. You should get two files in `csv` format: ss15pxx.csv and ss15hxx.csv where xx stands for your state's abbreviation and p and h represent the population and household-level PUMS, respectively.\n",
    "\n",
    "4. Download the PUMA 2010 shapefile for your state from [this link](https://www.census.gov/cgi-bin/geo/shapefiles/index.php?year=2010&layergroup=Public+Use+Microdata+Areas) and save to your `input` folder. \n",
    "    - Note that you may use this shapefile in a GIS suite to filter the data creation step to PUMAs within a certain area of interest (such as a metropolitan region).\n",
    "    \n",
    "5. Now `cd` to your working dir, and we will begin preprocessing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART II. Preprocessing:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from __future__ import (\n",
    "    absolute_import, division, print_function, unicode_literals\n",
    ")\n",
    "import builtins\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "from doppelganger import (allocation,\n",
    "                          inputs,\n",
    "                          Configuration,\n",
    "                          HouseholdAllocator,\n",
    "                          PumsData,\n",
    "                          SegmentedData,\n",
    "                          BayesianNetworkModel,\n",
    "                          Population,\n",
    "                          Preprocessor,\n",
    "                          Marginals)\n",
    "from download_allocate_generate import *\n",
    "import logging\n",
    "\n",
    "\n",
    "logging.basicConfig(filename='logs', filemode='a', level=logging.INFO)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AOI Loading\n",
    "This step loads the PUMAs in your AOI. This should have been completed using a GIS software with the shapefile downloaded in Part I."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load pumas (these will be based on the pumas you actually want to generate data for.)\n",
    "puma_df = pd.read_csv('input/sfbay_puma_from_intersection.csv',dtype=str)\n",
    "# Select 2010 PUMA column for filtering\n",
    "puma_df_clean = puma_df.PUMACE10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter PUMS data\n",
    "\n",
    "__NOTE__: If you've previously completed this task, uncomment appropriate parts below to load intermediate data outputs for further processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If filtering PUMS data for the first time\n",
    "Run the following to filter PUMS data (only if it's your first time running this task):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sfeygin/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (107,108) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# Read in population level PUMS (may take a while...)\n",
    "person_pums_df = pd.read_csv('input/ss14pca.csv', na_values=['N.A'],na_filter=True)\n",
    "# Read in household level PUMS (may take a while...)\n",
    "household_pums_df = pd.read_csv('input/ss14hca.csv', na_values=['N.A'],na_filter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter household data and population data to AOI\n",
    "person_df_in_aoi=person_pums_df[person_pums_df['PUMA10'].isin(puma_df_clean.values)]\n",
    "person_df_in_aoi.loc[:,'puma']=person_df_in_aoi['PUMA10']\n",
    "household_df_in_aoi=household_pums_df[household_pums_df['PUMA10'].isin(puma_df_clean.values)]\n",
    "household_df_in_aoi.loc[:,'puma']=person_df_in_aoi['PUMA10']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save for later use\n",
    "person_df_in_aoi.to_csv('input/sfbay_person_pums_data.csv',index_label='index')\n",
    "household_df_in_aoi.to_csv('input/sfbay_household_pums_data.csv',index_label='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Otherwise, load Previously Filtered PUMS Data:\n",
    "\n",
    "Uncomment below if starting from outputs of previous step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# houshold_df_in_aoi=pd.read_csv('input/sfbay_household_pums_data.csv')\n",
    "# person_df_in_aoi=pd.read_csv('input/sfbay_person_pums_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Constants for Analysis  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "STATE = '06'  # change to your state as appropriate\n",
    "PUMA = puma_df_clean.iloc[0]\n",
    "TABLENAME='acs_2015_5yr_pums'\n",
    "output_dir = 'output'\n",
    "census_api_key = '4d1ff8f7278171c404244dbe3055addfb97757c7'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Doppelganger example configuration file\n",
    "This file does the following three things:\n",
    "1. Defines person-specific variables in `person_fields`. In the example, you'll see `age`, `sex`, and `individual_income`. These variables are mapped to the PUMS variables in `inputs.py`. For example, `age` in Doppelganger is mapped to the PUMS variable `agep`. To use other variables from the PUMS with Doppelganger, you'll need to map their relationships in `inputs.py` and specify them here. \n",
    "2. Defines household-specific variables in `household_fields`. In the example, you'll see `household_income` and `num_vehicles`. As with the person-specific variables, you'll need to modify `inputs.py` to use other variables in Doppelganger.\n",
    "3. Defines procedures to process input variables into bins in `preprocessing`.\n",
    "4. Defines the structure of the household and person Bayesian Networks in `network_config_files`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "configuration = Configuration.from_file('input/config.json')\n",
    "household_fields = tuple(set(\n",
    "    field.name for field in allocation.DEFAULT_HOUSEHOLD_FIELDS).union(\n",
    "        set(configuration.household_fields)\n",
    "))\n",
    "persons_fields = tuple(set(\n",
    "    field.name for field in allocation.DEFAULT_PERSON_FIELDS).union(\n",
    "        set(configuration.person_fields)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen_pumas = ['state_06_puma_{}_generated.csv'.format(puma) for puma in puma_df_clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'allocator' referenced before assignment",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-ffa41da6e3e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m     marginals, allocator = download_tract_data(\n\u001b[1;32m     28\u001b[0m                 \u001b[0mSTATE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpuma_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcensus_api_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpuma_tract_mappings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                 \u001b[0mhouseholds_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpersons_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m             )\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sfeygin/current_code/python/examples/doppelganger/examples/download_allocate_generate.py\u001b[0m in \u001b[0;36mdownload_tract_data\u001b[0;34m(state_id, puma_id, output_dir, census_api_key, puma_tract_mappings, households_data, persons_data)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmarginals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallocator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'allocator' referenced before assignment"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "pumas_to_go = set(puma_df_clean.values.tolist())\n",
    "\n",
    "for puma in puma_df_clean:\n",
    "    gen_puma ='state_06_puma_{}_generated.csv'.format(puma)\n",
    "    if gen_puma in os.listdir('.'):\n",
    "        print (puma)\n",
    "        pumas_to_go.remove(puma)\n",
    "        \n",
    "\n",
    "puma_tract_mappings='input/2010_puma_tract_mapping.txt'\n",
    "configuration = Configuration.from_file('input/config.json')\n",
    "preprocessor = Preprocessor.from_config(configuration.preprocessing_config)\n",
    "\n",
    "for puma_id in pumas_to_go:\n",
    "    households_data = PumsData.from_csv('input/sfbay_household_pums_data.csv').clean(household_fields, preprocessor, state=STATE, puma=puma_id)\n",
    "    persons_data = PumsData.from_csv('input/sfbay_person_pums_data.csv').clean(persons_fields, preprocessor,state=STATE, puma=puma_id)\n",
    "    population_segmenter = lambda x: None\n",
    "    household_segmenter = lambda x: None\n",
    "    print(\"loaded\")\n",
    "    \n",
    "    household_model, person_model = create_bayes_net(\n",
    "            STATE, puma_id, output_dir,\n",
    "            households_data, persons_data, configuration,\n",
    "            person_segmenter, household_segmenter\n",
    "        )\n",
    "\n",
    "    marginals, allocator = download_tract_data(\n",
    "                STATE, puma_id, output_dir, census_api_key, puma_tract_mappings,\n",
    "                households_data, persons_data\n",
    "            )\n",
    "    \n",
    "    print('Allocated {}'.format(puma_id))\n",
    "    population = generate_synthetic_people_and_households(\n",
    "                STATE, puma_id, output_dir, allocator,\n",
    "                person_model, household_model\n",
    "            )\n",
    "    \n",
    "    print('Generated {}'.format(puma_id))\n",
    "    accuracy = Accuracy.from_doppelganger(\n",
    "            cleaned_data_persons=persons_data,\n",
    "            cleaned_data_households=households_data,\n",
    "            marginal_data=marginals,\n",
    "            population=population\n",
    "        )\n",
    "    \n",
    "    logging.info('Absolute Percent Error for state {}, and puma {}: {}'.format(STATE, puma_id,\n",
    "                     accuracy.absolute_pct_error().mean()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_comb=dd.read_csv('state_06_puma_*_generated.csv')\n",
    "df_next=df_comb[['tract','num_people','num_vehicles','household_id_x','serial_number','repeat_index']]\n",
    "df_next.compute().to_csv('combined_pop.csv')\n",
    "df=pd.read_csv('combined_pop.csv')\n",
    "df.num_people=df.num_people.replace('4+',4).astype(int)\n",
    "tract_sd=pd.concat([df['num_people']['std'],df['num_vehicles']['std']],axis=1)\n",
    "tract_sd.columns=['hh_sd','car_sd']\n",
    "\n",
    "tract_sd_df=pd.DataFrame(tract_sd)\n",
    "tract_sd_df['tract']=tract_sd_df.index\n",
    "merged_gdf=merged_gdf.merge(tract_sd_df,on='tract')\n",
    "df=df.drop(['Unnamed: 0','serial_number','repeat_index','person_id'],axis=1)\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "def compute_row(i):\n",
    "    row = df.iloc[i]\n",
    "    tract_no = row.tract\n",
    "    pt = get_random_point_in_polygon(tract_gdf[(tract_no == tract_gdf.tract)].geometry.values[0])\n",
    "    return np.array([str(row.household_id_x),int(row.num_people),int(row.num_vehicles),float(pt.x),float(pt.y)])\n",
    "\n",
    "res = []\n",
    "for i in tnrange(df.shape[0], desc='1st loop'):\n",
    "    res.append(compute_row(i))\n",
    "out_df=dd.from_array(res).compute()\n",
    "out_df.to_csv(\"output/hhOut.csv\",header=False,index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
